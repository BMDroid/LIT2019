{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = iris.sort_values(by=['WinOrLose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(iris[:60].MarksSimilarity, iris[:60].AuralSimilarity, label='Lose')\n",
    "plt.scatter(iris[-60:].MarksSimilarity, iris[-60:].AuralSimilarity, label='Win')\n",
    "plt.xlabel('Marks Similarity')\n",
    "plt.ylabel('Visual Similarity')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop(labels=['WinOrLose'], axis=1).values\n",
    "Y = iris.WinOrLose.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for numpy and tensorflow\n",
    "# set for reproducible results\n",
    "seed = 5\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set replace=False, Avoid double sampling\n",
    "trainIndex = np.random.choice(len(X), round(len(X) * 0.8), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff set\n",
    "testIndex = np.array(list(set(range(len(X))) - set(trainIndex)))\n",
    "trainX = X[trainIndex]\n",
    "trainY = Y[trainIndex]\n",
    "testX = X[testIndex]\n",
    "testY = Y[testIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the normalized function\n",
    "def min_max_normalized(data):\n",
    "    colMax = np.max(data, axis=0)\n",
    "    colMin = np.min(data, axis=0)\n",
    "    return np.divide(data - colMin, colMax - colMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized processing, must be placed after the data set segmentation, \n",
    "# otherwise the test set will be affected by the training set\n",
    "trainX = min_max_normalized(trainX)\n",
    "testX = min_max_normalized(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin building the model framework\n",
    "# Declare the variables that need to be learned and initialization\n",
    "# There are 6 features here, A's dimension is (6, 1)\n",
    "W = tf.Variable(tf.random_normal(shape=[6, 1]), name='W')\n",
    "b = tf.Variable(tf.random_normal(shape=[1, 1]), name= 'b')\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define placeholders\n",
    "data = tf.placeholder(dtype=tf.float32, shape=[None, 6])\n",
    "target = tf.placeholder(dtype=tf.float32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the model you need to learn\n",
    "model = tf.matmul(data, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare loss function\n",
    "# Use the sigmoid cross-entropy loss function,\n",
    "# first doing a sigmoid on the model result and then using the cross-entropy loss function\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=modedl, labels=target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the learning rateï¼Œ batch_size etc.\n",
    "learning_rate = 0.003\n",
    "batch_size = 40\n",
    "iter_num = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the goal\n",
    "goal = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the accuracy\n",
    "# The default threshold is 0.5, rounded off directly\n",
    "prediction = tf.round(tf.sigmoid(mod))\n",
    "# Bool into float32 type\n",
    "correct = tf.cast(tf.equal(prediction, target), dtype=tf.float32)\n",
    "# Average\n",
    "accuracy = tf.reduce_mean(correct)\n",
    "# End of the definition of the model framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training model\n",
    "# Define the variable that stores the result\n",
    "loss_trace = []\n",
    "train_acc = []\n",
    "test_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model\n",
    "for epoch in range(iter_num):\n",
    "    # Generate random batch index\n",
    "    batchIndex = np.random.choice(len(trainX), size=batch_size)\n",
    "    batchTrainX = trainX[batchIndex]\n",
    "    batchTrainY = np.matrix(trainY[batchIndex]).T\n",
    "    sess.run(goal, feed_dict={data: batchTrainX, target: batchTrainY})\n",
    "    temp_loss = sess.run(loss, feed_dict={data: batchTrainX, target: batchTrainY})\n",
    "    # convert into a matrix, and the shape of the placeholder to correspond\n",
    "    temp_train_acc = sess.run(accuracy, feed_dict={data: trainX, target: np.matrix(trainY).T})\n",
    "    temp_test_acc = sess.run(accuracy, feed_dict={data: testX, target: np.matrix(testY).T})\n",
    "    # recode the result\n",
    "    loss_trace.append(temp_loss)\n",
    "    train_acc.append(temp_train_acc)\n",
    "    test_acc.append(temp_test_acc)\n",
    "    # output\n",
    "    if (epoch + 1) % 300 == 0:\n",
    "        print('epoch: {:4d} loss: {:5f} train_acc: {:5f} test_acc: {:5f}'.format(epoch + 1, temp_loss,\n",
    "                                                                          temp_train_acc, temp_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the results\n",
    "# loss function\n",
    "plt.plot(loss_trace)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "plt.plot(train_acc, 'b-', label='train accuracy')\n",
    "plt.plot(test_acc, 'k-', label='test accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Train and Test Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars = tf.trainable_variables()\n",
    "# vars_vals = sess.run(vars)\n",
    "# for var, val in zip(vars, vars_vals):\n",
    "#    print(\"var: {}, value: {}\".format(var.name, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
