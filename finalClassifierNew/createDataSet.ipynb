{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import string\n",
    "import operator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_name_list(cate):\n",
    "    fileList = os.listdir('./{}'.format(cate))\n",
    "    if '.DS_store' in fileList:\n",
    "        fileList.remove('.DS_store ')\n",
    "    fileNameList = list(map(lambda x: './{}/{}'.format(cate, x), fileList))\n",
    "    return fileNameList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_html(fileName):\n",
    "    html = io.open(fileName, mode=\"r\", encoding=\"utf-8\")\n",
    "    soup = BeautifulSoup(html, 'html.parser') \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stop_words(stopFileName):\n",
    "    file = open(stopFileName, mode=\"r\", encoding=\"utf-8\")\n",
    "    words = list(map(lambda x: x[0:-1], file.readlines()))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s, stopWords):\n",
    "    puncs = string.punctuation.translate({ord('('): None, ord(')'): None}) + '’' + '“' + '”' + '\\\\'\n",
    "    return list(map(lambda x: x.lower(), list(filter(lambda x:  4 < len(x) <= 16 and not any(p in x for p in puncs) and x not in stopWords and x.count('(') == x.count(')'), s.split(' ')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_contents(soup, className):\n",
    "    lst = soup.find_all(class_=className)\n",
    "    text = ''.join([''.join(l.findAll(text=True)) + ' ' for l in lst])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter_vectorizer(text, wordsBag):\n",
    "    vecLength = len(wordsBag)\n",
    "    vec = [None] * vecLength\n",
    "    for idx, word in enumerate(wordsBag):\n",
    "        vec[idx] = text.count(word)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(fileNameList, wordsBag, className='txt-body', stopWords='./stopWords.txt'):\n",
    "    dataSet = []\n",
    "    for file in fileNameList: \n",
    "        vec = []\n",
    "        soup = read_html(file)\n",
    "        text = class_contents(soup, className)\n",
    "        cleanText = clean_text(text, read_stop_words(stopWords))\n",
    "        countVec = word_counter_vectorizer(cleanText, wordsBag)\n",
    "        if file[2] == 'A':\n",
    "            label = [1]\n",
    "        else:\n",
    "            label = [-1]\n",
    "        countVec.extend(label)\n",
    "        dataSet.append(countVec)\n",
    "    return dataSet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trade Mark Cases\n",
    "cateA = 'A'\n",
    "fileNameListA = file_name_list(cateA)\n",
    "\n",
    "# Non Trade Mark Cases\n",
    "cateB = 'B'\n",
    "fileNameListB = file_name_list(cateB)\n",
    "\n",
    "# Combined\n",
    "fileNameList = fileNameListA + fileNameListB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = read_stop_words('./stopWords.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words Bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsBag = ['likelyhood', 'breach', 'trade', 'evidence', 'property', 'public', 'opponents', 'constitution', 'fiduciary', 'confusion', 'crimes', 'copyright', 'intellectual', 'misuse', 'death', 'marks', 'constitutional', 'unregistered', 'contract', 'drugs', 'proprietor', 'similar', 'penalty', 'company', 'criminal'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = create_dataset(fileNameList, wordsBag.append('Label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"data.csv\", dataSet, fmt='%i', delimiter=\",\", header=','.join(wordsBag))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
